{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1PWwFyRPCHkKT1mnGKxMVASgWtRpDSMbL","authorship_tag":"ABX9TyMy5lQ/wHmsZNcta7iX5pGx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<img src=\"https://www.aepia.org/wp-content/uploads/2022/04/logo-aepia.png\" width=\"200\"/>\n","\n","<img src=\"https://i1.rgstatic.net/ii/lab.file/AS%3A608742152355841%401522146847661_xl\" width=\"300\"/>\n","\n","<img src=\"https://www.upo.es/cms1/export/sites/upo/comunicacion/imagenes/mic-upo-descargas/Marca-UPO-Horizontal.png\" width=\"200\"/>\n","\n","\n","\n","# **Deep Learning: Image classification**\n","## Escuela de verano de Inteligencia Artificial 2023\n","#### José Fco. Torres Maldonado\n","\n","jftormal@upo.es | datalab.upo.es/torres"],"metadata":{"id":"4pEBMeGzVJoR"}},{"cell_type":"markdown","source":["---\n","\n"],"metadata":{"id":"ugLutmNdrieT"}},{"cell_type":"code","source":["# Importar librerías\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","import matplotlib.pyplot as plt\n","from imutils import paths\n","import keras as keras\n","import os\n","import cv2\n","import zipfile\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"fdlytt8ds10j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Dataset: 25000 fotografías de perros y gatos\n","\n","Formato .zip<br/>\n","Nombradas como: cat.XXXX.jpg y dog.XXXX.jpg"],"metadata":{"id":"OYXT4szVVTH1"}},{"cell_type":"code","source":["zip = zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/EVIA2023/dataset.zip\", 'r')\n","zip.extractall(\"/\")\n","zip.close()"],"metadata":{"id":"hClDl-SFqQ4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Número de imágenes: \", len(os.listdir(\"/dataset\")))\n","print(\"Contenido: \", os.listdir(\"/dataset\"))"],"metadata":{"id":"xeLDVCMNzi0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = cv2.imread('/dataset/dog.7182.jpg')\n","\n","imgrgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","imggray = cv2.cvtColor(imgrgb, cv2.COLOR_RGB2GRAY)\n","img50x50 = cv2.resize(imggray, (50, 50))\n","\n","fig, axs = plt.subplots(1, 4, figsize=(10, 10))\n","axs[0].imshow(img)\n","axs[1].imshow(imgrgb)\n","axs[2].imshow(imggray, cmap='gray')\n","axs[3].imshow(img50x50, cmap=\"gray\")\n","\n","plt.show()"],"metadata":{"id":"IGJljN7oz7ZC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Preprocesado"],"metadata":{"id":"CUgxdChK7Z39"}},{"cell_type":"code","source":[],"metadata":{"id":"adX1uCt18Ewh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = []\n","labels = []\n","\n","listaImagenes = list(paths.list_images('/dataset'))\n","print(listaImagenes[0:5])"],"metadata":{"id":"lnq6h0JS89PW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for (i, imgpath) in enumerate(listaImagenes):\n","    img = cv2.imread(imgpath)\n","    label = imgpath.split(os.path.sep)[-1].split(\".\")[0]\n","    features = image_as_vector(img)\n","    data.append((features, imgpath))\n","    labels.append(label)"],"metadata":{"id":"wM9zAOoO89C5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Total de imágenes:\",len(data))\n","print(\"Registro:\", data[0])\n","print(\"Imagen:\", data[0][0])\n","print(\"Tamaño de cada imagen:\", len(data[0][0])) #Equivale a 50x50x3 canales\n","print(\"Ruta:\", data[0][1])\n","print(\"Etiqueta:\", labels[0])"],"metadata":{"id":"meN36cgZ89CW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imagesdata = [dat[0] for dat in data]\n","imagespaths = [dat[1] for dat in data]\n","\n","print(imagesdata[0])\n","print(imagespaths[0])"],"metadata":{"id":"i7j7B8sq89Bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = LabelEncoder()\n","labels = encoder.fit_transform(labels)\n","\n","imgdata = np.array(imagesdata) / 255.0\n","labels = np_utils.to_categorical(labels,2)"],"metadata":{"id":"oHNhzOpY89BM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Imagen de ejemplo:\",imgdata[0])\n","print(\"Etiqueta de ejemplo:\",labels[0])"],"metadata":{"id":"XziwN8mW88rp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(X_train, X_test, y_train, y_test, trainingpaths, testpaths) = train_test_split(imgdata, labels, imagespaths, test_size=0.30, random_state=42)"],"metadata":{"id":"qepy7G0u88i_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Tamaño del training:\", len(X_train))\n","print(\"Tamaño del test:\", len(X_test))"],"metadata":{"id":"nVjxRutNATmI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Modelos Deep Learning"],"metadata":{"id":"BP34dKue8RYt"}},{"cell_type":"markdown","source":["### 3.1 Convolutional Neural Network (CNN)"],"metadata":{"id":"OT66rAvO-SfC"}},{"cell_type":"code","source":[],"metadata":{"id":"-oVE7DgPwp3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BXwfDEQvwpvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnnmodel.summary()\n","\n","# Gráfica de la pérdida durante el entrenamiento\n","plt.figure(figsize=(12, 6))\n","plt.plot(cnnhistory.history['loss'])\n","plt.title('Pérdida durante el entrenamiento')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.show()"],"metadata":{"id":"v_u2dQs2xGVy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(loss, accuracy) = cnnmodel.evaluate(X_test, y_test, batch_size=128, verbose=1)\n","print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy*100))"],"metadata":{"id":"p1v___q5xGTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probabilities = cnnmodel.predict(X_test)\n","predictions = np.round(np.argmax(probabilities, axis=1)).astype(int)"],"metadata":{"id":"A61odbWmxGQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["real = np.argmax(y_test, axis=1) # y_test contiene por cada imagen un vector [X,Y]. Si X vale 1 -> gato; si Y vale 1 -> perro. Esta línea se queda con el índice para saber si es clase 0 (gato) o clase 1 (perro). codificación ONE-HOT"],"metadata":{"id":"XoAg-vjYDhew"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Análisis de las predicciones"],"metadata":{"id":"WNNHyPBX_XAn"}},{"cell_type":"code","source":["def mostrar_resultado(idImagen):\n","    clase_real = \"gato\" if real[idImagen] == 0 else \"perro\"\n","    clase_predicha = \"gato\" if predictions[idImagen] == 0 else \"perro\"\n","    rutabase = \"/dataset\"\n","    fullpath = testpaths[idImagen]\n","    image = cv2.imread(fullpath)\n","    imgrgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    plt.imshow(imgrgb)\n","    plt.axis('off')\n","    plt.show()\n","    print(\"CLASE REAL: \\t\", clase_real)\n","    print(\"CLASE PREDICHA:\\t\", clase_predicha)\n","    return fullpath"],"metadata":{"id":"zZQVw_2dazCr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mostrar_resultado(1444)"],"metadata":{"id":"YtGdGdUfq-7R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calcular la exactitud (accuracy)\n","accuracy = accuracy_score(real, predictions)\n","print(\"ACC (%): \", accuracy*100)\n","\n","# Calcular la precisión (precision)\n","precision = precision_score(real, predictions)\n","print(\"precision : \", precision)\n","\n","# Calcular la exhaustividad (recall)\n","recall = recall_score(real, predictions)\n","print(\"recall : \", recall)\n","\n","# Calcular la puntuación F1\n","f1 = f1_score(real, predictions)\n","print(\"F1 : \", f1)\n","\n","# Calcular el área bajo la curva ROC (AUC-ROC)\n","auc_roc = roc_auc_score(real, predictions)\n","print(\"AUC : \", auc_roc)"],"metadata":{"id":"EXIJB2ikEEm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(real, predictions)\n","print(cm)"],"metadata":{"id":"sz0QZ9NzIGwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BMX6VJxdXIaY"},"execution_count":null,"outputs":[]}]}